

[
  
  
    
    
      {
        "title": "Meu primeiro projeto em Data Science",
        "excerpt": "Nesse post pretendo descrever meu primeiro projeto de Ciência de Dados. O projeto consiste em estudar os dados da Trimania que são disponibilizados no site da instituição. Nele eu levantei informações bem simples, como: números sorteados e bairros que mais tiveram ganhadores em um período.\n",
        "content": "English Version\n\nNesse post pretendo descrever meu primeiro projeto de Ciência de Dados. O projeto consiste em estudar os dados da Trimania que são disponibilizados no site da instituição. Nele eu levantei informações bem simples, como: números sorteados e bairros que mais tiveram ganhadores em um período.\n\nComo obtive os dados\n\nPara obter os dados eu criei um crawler. O mesmo foi desenvolvido em PHP utilizando uma biblioteca do framework Symfony. As informações recebidas são salvas em duas tabelas: uma para localização e outra para os números.\n\n\n\nUma das dificuldades para executar esse projeto é o tratamento de dados. Sempre que importado um conjunto de dados foi necessário realizar o tratamento deles, pois, constantemente o nome das cidades divergiam. Como exemplo em sorteios que existem ganhadores na cidade Joinville. No site os dados eram apresentados da seguinte forma: “Bairro / Joinvillle”, “Joinvile/Bairro”, “Joinville /Bairro”. Abaixo alguns exemplos do problema citado no sorteio do dia 02/09/2018.\n\n\n\nNão realizando a correção desses dados a análise seria errônea. Na imagem seguinte é mostrada alguns bairros juntamente com a cidade após ter sido feita a correção dos caracteres.\n\n\n\nOs números sorteados não tem uma quantidade exata como na Mega-Sena, ou seja, a quantidade de números sorteados por rodada vai variar. Logo, não optei por ter uma coluna para cada valor sorteado. Criei uma coluna do tipo texto e salvei usando hífen como separador.\n\n\n\nAnálise dos números\n\nComo este projeto é para estudos eu criei uma pergunta que eu gostaria de responder, a pergunta que elaborei foi ‘Quais os números mais sorteados de Janeiro a Abril de 2018?’. Para conseguir a resposta comecei exportando um CSV e depois utilizei o Jupyter Notebook para analisar.\n\n# Nesta linha eu faço a leitura do arquivo e mostro uma prévia do que foi importado.\ncsv = pd.read_csv('trimaniaNumbers.csv', delimiter=';');\ncsv\n\n\n\n\n# Dicionário para inserir os números\nnumbers = {\n    'number':[]\n}\n\n# Separando os números por hífen e acrescentado os números no dicionário\nfor lines in csv['numbers_drawn']:    \n    for number in lines.split('-'):\n            numbers['number'].append(number)\n        \n\n# Utilizei o dicionado para gerar um novo DataFrame\ndf = pd.DataFrame(numbers)\n\n# Conto os números repetidos e solicito os 20 primeiros \ndata = df['number'].value_counts().head(20)\n\n\nPara visualizar de maneira mais amigável, gerei um gráfico de Números X Quantidade.\n\n# Configuro a fonte\nfont = {\n    'weight': 'normal',\n    'size': 16\n}\n\n# Configuro a label dos eixos X e Y\nplt.xlabel('Numbers', fontdict=font)\nplt.ylabel('Quantity', fontdict=font)\n\n# Exibo um gráfico em barra\ndata.plot(kind='bar')\nplt.show()\n\n\n\n\nAnálise das localizações\n\nNo estudo das localizações também elaborei uma pergunta: ‘Quais os bairros que mais tiveram ganhadores entre Janeiro e Abril de 2018 na cidade de Joinville?’. Para conseguir a resposta para tal pergunta fiz apenas uma SQL simples.\n\nSELECT COUNT(*) AS total, city_district\nFROM locations\nWHERE draw_date BETWEEN '2018-01-01' AND '2018-04-30'\n      AND city_district like '%/Joinville%'\nGROUP BY city_district\nORDER BY total DESC\n\nApós executar a SQL acima eu obtive a minha resposta:\n\n\n\nConsiderações\n\nEste projeto não possui muitas complexidades. Ainda preciso melhorar meus conhecimentos construindo desafios mais complexos. Mesmo assim acredito que este exerício tem um grande valor. Se você tiver alguma dúvida ou sugestão, fique a vontade para comentar :)\n",
        "url": "/2019/03/17/primeiro-projeto-ciencia-de-dados/"
      },
    
      {
        "title": "My first project with Data Science",
        "excerpt": "In this post, I pretend to describe my first project with Data Science. The project consists to study Trimania data that are available on its site. On this project, I got simple information like drawn numbers e neighborhoods with most winners\n",
        "content": "Portuguese Version\n\nIn this post, I pretend to describe my first project with Data Science. The project consists to study Trimania data that are available on its site. On this project, I got simple information like drawn numbers e neighborhoods with most winners.\n\nHow I got data\n\nTo get data I built a crawler. It was developed with PHP and a Symfony’s library. The informations received are storage on two tables on database. One is for locations and other for numbers.\n\n\n\nThe main difficulty to carry out this project is clean data. Always that imported a set of data was needed to realize data cleaning because constantly the city name came wrong. As an example in draws where there are winners in Joinville. On site, the data are shown like this: “Bairro / Joinvillle”, “Joinvile/Bairro”, “Joinville /Bairro”. Below some example about the problem on 2nd September 2018.\n\n\n\nIf I didn’t the data correction, the analysis would be got wrong. The next image is shown some neighborhoods with the city after data cleaning.\n\n\n\nThe drawn numbers don’t have an exact quantity like Mega-Sena, in other words, the quantity of drawn number will variate. Then I’ve decided to create one column for all numbers and separate them by a hyphen.\n\n\n\nAnalysis of the numbers\n\nIn this project I created a question that I would like to answer, so the question I elaborated was ‘What are the most numbers drawn between January and April of 2018?’. To get this I exported a CSV file and after I used the Jupyter Notebook to analyze.\n\n# On this line, I read and show a preview of what was imported\ncsv = pd.read_csv('trimaniaNumbers.csv', delimiter=';');\ncsv\n\n\n\n\n# Dictionary to insert the numbers\nnumbers = {\n    'number':[]\n}\n\n# Separating the numbers by a hyphen and adding on a dictionary\nfor lines in csv['numbers_drawn']:    \n    for number in lines.split('-'):\n            numbers['number'].append(number)\n        \n\n# I used the dictionary to generate a new DataFrame\ndf = pd.DataFrame(numbers)\n\n# I count the quantity repeated numbers quantity and I get the twenty-first\ndata = df['number'].value_counts().head(20)\n\n\nTo view a way nicier, I generate a chart of Numbers X Quantity.\n\n# Configuration the font\nfont = {\n    'weight': 'normal',\n    'size': 16\n}\n\n# Configuration the labels from axes X and Y\nplt.xlabel('Numbers', fontdict=font)\nplt.ylabel('Quantity', fontdict=font)\n\n# It is displayed a bar chart\ndata.plot(kind='bar')\nplt.show()\n\n\n\n\nAnalysis of the locations\n\nOn the study of the locations also I created another question ‘What the neighborhoods had the most winners between January and April of 2018 in Joinville?’. To answer such question I made only a simple SQL.\n\nSELECT COUNT(*) AS total, city_district\nFROM locations\nWHERE draw_date BETWEEN '2018-01-01' AND '2018-04-30'\n      AND city_district like '%/Joinville%'\nGROUP BY city_district\nORDER BY total DESC\n\nAfter to execute I got my answer.\n\n\n\nConsiderations\n\nThis project there no many complexities. I still need to improve my skills building challenges more complex. Even so, I believe this exercise has great value. If you have some doubt or suggestion, feel free to comment :)\n",
        "url": "/2019/03/17/first-project-data-science/"
      },
    
      {
        "title": "Média salarial de Alagoas",
        "excerpt": "Este exercício é de um curso da Udemy que eu fiz. No curso, eu precisei fazer uma tabela com valores estatísticos (média, mediana, desvio padrão, etc…). Então eu decidi fazer o mesmo exercício com Python e suas bibliotecas\n",
        "content": "English Version\n\nEste exercício é de um curso da Udemy que eu fiz. No curso, eu precisei fazer uma tabela com valores estatísticos (média, mediana, desvio padrão, etc…). Então eu decidi fazer o mesmo exercício com Python e suas bibliotecas.\n\nO professor do curso providenciou uma planilha com dados do Censo do IBGE de 2010. Foi incluído neste exerício uma amostra com trinta cidades e também definido que seria usado a amostra estratificada por causa das mesorregiões.\n\nO meu primeiro passo foi criar uma nova planilha usando os valores da planilha original para tornar meu trabalho mais fácil, depois exportei para um arquivo CSV e importe usando Pandas.\n\n# Importo o CSV, defino ponto e vírgula como um delimitador e informo que NaN é referente a valores nulos\ndata = pd.read_csv(\"CidadesAlagoas.csv\", delimiter=';', keep_default_na=False, na_values=['NaN'])\n\n# Definido número da amostra\nNUM_SAMPLE = 30\n\n# Os filtros da cidade por mesorregião\nfilter_agreste = data[data['mesoregion'] == 'Agreste Alagoano']\nfilter_sertao  = data[data['mesoregion'] == 'Sertão Alagoano']\nfilter_leste   = data[data['mesoregion'] == 'Leste Alagoano']\n\nCada mesorregião tem um número de cidades que precisam ser sorteads e separadas proporcionamente. Para escolher as cidades, Eu contei o total de cidades por mesorregião.\n\nnumber_cities_agreste = len(filter_agreste)\nnumber_cities_sertao  = len(filter_sertao) \nnumber_cities_leste   = len(filter_leste)\nnumber_cities = len(data)\n\nprint ('''\nNúmero de cidades do Agreste Alagoano: %d\nNúmero de cidades do Sertão Alagoano: %d\nNúmero de cidades do Leste Alagoano: %d\n''' %(number_cities_agreste, number_cities_sertao, number_cities_leste))\n\n#-------------------OUT-------------------#\n# Número de cidades do Agreste Alagoano: 24\n# Número de cidades do Sertão Alagoano: 26\n# Número de cidades do Leste Alagoano: 52\n#-------------------OUT-------------------#\n\nDepois disto, eu calculei o peso para cada mesorregião divindo o total de cidades de cada mesorregião pelo total de cidades do estado.\n\nweight_agreste = float(number_cities_agreste)/number_cities\nweight_sertao  = float(number_cities_sertao)/number_cities\nweight_leste   = float(number_cities_leste)/number_cities\n\nprint ('''\nPeso do Agreste Alagoano: %.2f\nPeso do Sertão Alagoano: %.2f\nPeso do Leste Alagoano: %.2f\n''' %(weight_agreste, weight_sertao, weight_leste))\n\n#-----------------OUT---------------#\n# Peso do Agreste Alagoano: 0.24\n# Peso do Sertão Alagoano: 0.25\n# Peso do Leste Alagoano: 0.51\n#-----------------OUT---------------#\n\nAnd then I got the sure quantity cities by mesoregion making a multiplication with weight and total samples.\n\nnumber_draw_cities_agreste = int(round(weight_agreste * NUM_SAMPLE))\nnumber_draw_cities_sertao  = int(round(weight_sertao * NUM_SAMPLE))\nnumber_draw_cities_leste   = int(round(weight_leste * NUM_SAMPLE))\n\nprint ('''\nNúmero de cidades para sortear in Agreste Alagoano: %.d\nNúmero de cidades para sortear in Sertão Alagoano: %.d\nNúmero de cidades para sortear in Leste Alagoano: %.d\n''' %(number_draw_cities_agreste, number_draw_cities_sertao, number_draw_cities_leste))\n\n#-------------------------OUT------------------------------#\n# Número de cidades para sortear no Agreste Alagoano: 7\n# Número de cidades para sortear no Sertão Alagoano: 8\n# Número de cidades para sortear no Leste Alagoano: 15\n#-------------------------OUT------------------------------#\n\nCom o número de cidades, eu as sortei assim.\n\n# O primeiro parametro é a quantiade e eu defino 'replace' como falso para não repetir \ndraw_agreste = filter_agreste.sample(n=number_draw_cities_agreste, replace=False)\ndraw_sertao  = filter_sertao.sample(n=number_draw_cities_sertao, replace=False)\ndraw_leste   = filter_leste.sample(n=number_draw_cities_leste, replace=False)\n\n# Criei um DataFrame para cada mesorregião\nagreste = pd.DataFrame(draw_agreste)\nsertao = pd.DataFrame(draw_sertao)\nleste  = pd.DataFrame(draw_leste)\n\n# Juntei todas as mesorregiões\nnew_data = pd.concat([agreste, sertao, leste])\n\n# Então aqui eu mostrao o DataFrame\nnew_data\n\n\n\n\nCom as cidades sorteadas, precisei obter os valores pedidos (média, mediana, desvio padrão, coeficiente de variação, menor valor, maior valor, quartil de 25%, quartil de 75%, percentil de 10% e percentil de 90%).\n\n# A função describe algum dos valores por padrão\ndescribe = new_data.describe()\n\n# Criei um dicionário para organizar os valores por cargo\nresult = {\n    'with-clt': {\n        'mean': describe['with-clt']['mean'],\n        'median': new_data['with-clt'].median(),\n        'cv': (describe['with-clt']['std']/describe['with-clt']['mean'])*100,\n        'sd': describe['with-clt']['std'],\n        'min': describe['with-clt']['min'],\n        'max': describe['with-clt']['max'],\n        'q1': describe['with-clt']['25%'],\n        'q3': describe['with-clt']['75%'],\n        'p10': new_data['with-clt'].quantile(.10),\n        'p90': new_data['with-clt'].quantile(.90)\n        \n    },\n    'civil-servant': {\n        'mean': describe['civil-servant']['mean'],\n        'median': new_data['civil-servant'].median(),\n        'cv': (describe['civil-servant']['std']/describe['civil-servant']['mean'])*100,\n        'sd': describe['civil-servant']['std'],\n        'min': describe['civil-servant']['min'],\n        'max': describe['civil-servant']['max'],\n        'q1': describe['civil-servant']['25%'],\n        'q3': describe['civil-servant']['75%'],\n        'p10': new_data['civil-servant'].quantile(.10),\n        'p90': new_data['civil-servant'].quantile(.90)\n    },\n    'without-clt': {\n        'mean': describe['without-clt']['mean'],\n        'median': new_data['without-clt'].median(),\n        'cv': (describe['without-clt']['std']/describe['without-clt']['mean'])*100,\n        'sd': describe['without-clt']['std'],\n        'min': describe['without-clt']['min'],\n        'max': describe['without-clt']['max'],\n        'q1': describe['without-clt']['25%'],\n        'q3': describe['without-clt']['75%'],\n        'p10': new_data['without-clt'].quantile(.10),\n        'p90': new_data['without-clt'].quantile(.90)\n    },\n    'self-employed': {\n        'mean': describe['self-employed']['mean'],\n        'median': new_data['self-employed'].median(),\n        'cv': (describe['self-employed']['std']/describe['self-employed']['mean'])*100,\n        'sd': describe['self-employed']['std'],\n        'min': describe['self-employed']['min'],\n        'max': describe['self-employed']['max'],\n        'q1': describe['self-employed']['25%'],\n        'q3': describe['self-employed']['75%'],\n        'p10': new_data['self-employed'].quantile(.10),\n        'p90': new_data['self-employed'].quantile(.90)\n    },\n    'employer': {\n        'mean': describe['employer']['mean'],\n        'median': new_data['employer'].median(),\n        'cv': (describe['employer']['std']/describe['employer']['mean'])*100,\n        'sd': describe['employer']['std'],\n        'min': describe['employer']['min'],\n        'max': describe['employer']['max'],\n        'q1': describe['employer']['25%'],\n        'q3': describe['employer']['75%'],\n        'p10': new_data['employer'].quantile(.10),\n        'p90': new_data['employer'].quantile(.90)\n    }\n}\n\nPara finalizar o exercício, fiz um gráfico com as médias por cargo.\n\n\n\nConsiderações\n\nEste foi um outro exercócio que eu fiz para melhorar minhas habilidades. Se você tem alguma dúvida ou sugestão seu comentário é bem vindo :)\n",
        "url": "/2019/03/23/media-salarial-alagoas/"
      },
    
      {
        "title": "Mean Wage from Alagoas",
        "excerpt": "This exercise is from Udemy Course that I did. On the course, I needed to made a table with statistical values (mean, median, standard deviation, etc..). Then I decided to make the same exercise with Python and its libraries\n",
        "content": "Portuguese Version\n\nThis exercise is from Udemy Course that I did. On the course, I needed to make a table with statistical values (mean, median, standard deviation, etc..). Then I decided to make the same exercise with Python and its libraries.\n\nThe teacher of the course has provided a spreadsheet with data got for IBGE in 2010. It was included or this exercise was included a sample with thirty cities and also defined that would be used stratified sample because of mesoregions (Agreste, Leste e Sertão).\n\nMy first step was to create a new spreadsheet using the values from the original spreadsheet for became my work easier after I exported to CSV then I imported the using Pandas.\n\n# Import CSV, set semicolon as a delimiter and I inform that NaN is referring to null values\ndata = pd.read_csv(\"CidadesAlagoas.csv\", delimiter=';', keep_default_na=False, na_values=['NaN'])\n\n# Defined samples number (cities)\nNUM_SAMPLE = 30\n\n# The filters of cities by mesoregion\nfilter_agreste = data[data['mesoregion'] == 'Agreste Alagoano']\nfilter_sertao  = data[data['mesoregion'] == 'Sertão Alagoano']\nfilter_leste   = data[data['mesoregion'] == 'Leste Alagoano']\n\nEach mesoregion has a number of cities that need to be drawn and separated proportionally. To pick the cities, first I counted the total of cities by mesoregion.\n\nnumber_cities_agreste = len(filter_agreste)\nnumber_cities_sertao  = len(filter_sertao)\nnumber_cities_leste   = len(filter_leste)\nnumber_cities = len(data)\n\nprint ('''\nNumber of cities from Agreste Alagoano: %d\nNumber of cities from Sertão Alagoano: %d\nNumber of cities from Leste Alagoano: %d\n''' %(number_cities_agreste, number_cities_sertao, number_cities_leste))\n\n#-------------------OUT-------------------#\n# Number of cities from Agreste Alagoano: 24\n# Number of cities from Sertão Alagoano: 26\n# Number of cities from Leste Alagoano: 52\n#-------------------OUT-------------------#\n\n\nAfter this, I calculated the weight to each mesoregion dividing the total of cities from each mesoregion by total of cities from the state.\n\nweight_agreste = float(number_cities_agreste)/number_cities\nweight_sertao  = float(number_cities_sertao)/number_cities\nweight_leste   = float(number_cities_leste)/number_cities\n\nprint ('''\nWeight from Agreste Alagoano: %.2f\nWeight from Sertão Alagoano: %.2f\nWeight from Leste Alagoano: %.2f\n''' %(weight_agreste, weight_sertao, weight_leste))\n\n#-----------------OUT---------------#\n# Weight from Agreste Alagoano: 0.24\n# Weight from Sertão Alagoano: 0.25\n# Weight from Leste Alagoano: 0.51\n#-----------------OUT---------------#\n\n\nAnd then I got the sure quantity cities by mesoregion making a multiplication with weight and total samples.\n\nnumber_draw_cities_agreste = int(round(weight_agreste * NUM_SAMPLE))\nnumber_draw_cities_sertao  = int(round(weight_sertao * NUM_SAMPLE))\nnumber_draw_cities_leste   = int(round(weight_leste * NUM_SAMPLE))\n\nprint ('''\nNumber from cities for draw in Agreste Alagoano: %.d\nNumber from cities for draw in Sertão Alagoano: %.d\nNumber from cities for draw in Leste Alagoano: %.d\n''' %(number_draw_cities_agreste, number_draw_cities_sertao, number_draw_cities_leste))\n\n#-------------------------OUT------------------------------#\n# Number from cities to draw in Agreste Alagoano: 7\n# Number from cities to draw in Sertão Alagoano: 8\n# Number from cities to draw in Leste Alagoano: 15\n#-------------------------OUT------------------------------#\n\n\nWith the number of cities, I drew them like this.\n\n# The first parameter is the quantity and I set 'replace' as False for do not repeat\ndraw_agreste = filter_agreste.sample(n=number_draw_cities_agreste, replace=False)\ndraw_sertao  = filter_sertao.sample(n=number_draw_cities_sertao, replace=False)\ndraw_leste   = filter_leste.sample(n=number_draw_cities_leste, replace=False)\n\n# I created one DataFrame for each mesoregion\nagreste = pd.DataFrame(draw_agreste)\nsertao = pd.DataFrame(draw_sertao)\nleste  = pd.DataFrame(draw_leste)\n\n# I joined all mesoregions\nnew_data = pd.concat([agreste, sertao, leste])\n\n# Then here I show de DataFrame\nnew_data\n\n\n\n\nWith the cities drawn, I needed to get the values asked (mean, median, standard derivation, the coefficient of variation, lowest value, highest value, quantile 25%, quantile 75%, percentile 10% and percentile 90%).\n\n# Describe function shows some values for the default\ndescribe = new_data.describe()\n\n# I created a dictionary to organize the values by position\nresult = {\n    'with-clt': {\n        'mean': describe['with-clt']['mean'],\n        'median': new_data['with-clt'].median(),\n        'cv': (describe['with-clt']['std']/describe['with-clt']['mean'])*100,\n        'sd': describe['with-clt']['std'],\n        'min': describe['with-clt']['min'],\n        'max': describe['with-clt']['max'],\n        'q1': describe['with-clt']['25%'],\n        'q3': describe['with-clt']['75%'],\n        'p10': new_data['with-clt'].quantile(.10),\n        'p90': new_data['with-clt'].quantile(.90)\n        \n    },\n    'civil-servant': {\n        'mean': describe['civil-servant']['mean'],\n        'median': new_data['civil-servant'].median(),\n        'cv': (describe['civil-servant']['std']/describe['civil-servant']['mean'])*100,\n        'sd': describe['civil-servant']['std'],\n        'min': describe['civil-servant']['min'],\n        'max': describe['civil-servant']['max'],\n        'q1': describe['civil-servant']['25%'],\n        'q3': describe['civil-servant']['75%'],\n        'p10': new_data['civil-servant'].quantile(.10),\n        'p90': new_data['civil-servant'].quantile(.90)\n    },\n    'without-clt': {\n        'mean': describe['without-clt']['mean'],\n        'median': new_data['without-clt'].median(),\n        'cv': (describe['without-clt']['std']/describe['without-clt']['mean'])*100,\n        'sd': describe['without-clt']['std'],\n        'min': describe['without-clt']['min'],\n        'max': describe['without-clt']['max'],\n        'q1': describe['without-clt']['25%'],\n        'q3': describe['without-clt']['75%'],\n        'p10': new_data['without-clt'].quantile(.10),\n        'p90': new_data['without-clt'].quantile(.90)\n    },\n    'self-employed': {\n        'mean': describe['self-employed']['mean'],\n        'median': new_data['self-employed'].median(),\n        'cv': (describe['self-employed']['std']/describe['self-employed']['mean'])*100,\n        'sd': describe['self-employed']['std'],\n        'min': describe['self-employed']['min'],\n        'max': describe['self-employed']['max'],\n        'q1': describe['self-employed']['25%'],\n        'q3': describe['self-employed']['75%'],\n        'p10': new_data['self-employed'].quantile(.10),\n        'p90': new_data['self-employed'].quantile(.90)\n    },\n    'employer': {\n        'mean': describe['employer']['mean'],\n        'median': new_data['employer'].median(),\n        'cv': (describe['employer']['std']/describe['employer']['mean'])*100,\n        'sd': describe['employer']['std'],\n        'min': describe['employer']['min'],\n        'max': describe['employer']['max'],\n        'q1': describe['employer']['25%'],\n        'q3': describe['employer']['75%'],\n        'p10': new_data['employer'].quantile(.10),\n        'p90': new_data['employer'].quantile(.90)\n    }\n}\n\n\nTo finish the exercise I made a chart with the mean wage by position.\n\n\n\nConsiderations\n\nThis was another exercise that I made to improve my skills. So, if you have any doubt or suggestion your comment are welcome :)\n\n",
        "url": "/2019/03/23/mean-wage-alagoas/"
      },
    
      {
        "title": "Dicas para desenvolvimento com Wordpress",
        "excerpt": "Este texto é um pouco diferente dos anteriores onde falei assuntos que falavam sobre dados. Aqui pretendo ilustrar algumas dicas no desenvolvimento de projetos em Wordpress.\n",
        "content": "English Version\n\nEste texto é um pouco diferente dos anteriores onde falei assuntos que falavam sobre dados. Aqui pretendo ilustrar algumas dicas no desenvolvimento de projetos em Wordpress.\n\nTransaction\n\nMuitas vezes nós precisamos importar dados que serão utilizados para exibir em algum projeto. O processo de importação é passivel de erros quando está em atividade, logo precisamos garantir que em casos com problemas as informações não sejam importadas incompletas. Sendo assim, para esses casos o mais correto é utilizar as transactions. Claro, este é apenas um exemplo, as transactions podem ser usadas para outras finalidades que não tenham relação com alguma importação.\n\nfunction addPostExample() {\n\n    // Variável global do Wordpress\n    global $wpdb; \n    \n    // Iniciamos a transaction\n    $wpdb-&gt;query('START TRANSACTION');\n    \n    // Definimos algumas informações para o post\n    $postData = [\n        'post_title'     =&gt; 'Title example',  \n        'post_type'      =&gt; 'post-type-example',\n        'post_status'    =&gt; 'publish',\n        'comment_status' =&gt; 'closed',\n        'ping_status'    =&gt; 'closed'\n    ];\n    \n    // Inserimos o post\n    $postExample = wp_insert_post($postData, true);\n\n    // Possui erro?\n    if (is_wp_error($postExample)) {\n        \n        // Então fazemos o rollback\n        $wpdb-&gt;query('ROLLBACK');\n        return;\n    } \n    \n    // Não tem erro? Então é salvo o registro\n    $wpdb-&gt;query('COMMIT');\n        \n    // Retorna o id do post\n    return $postExample;\n}\n\n\nTruncate text\n\nUma situação que acontece muitas vezes é quando precisarmos exibir somente parte de um conteúdo, como por exemplo a prévia de um texto para chamar a atenção do leitor.\n\nTrabalhei em alguns projetos onde desenvolvedores fizeram uma função para cortar uma certa quantidade de palavras, mas não havia necessidade, pois o Wordpress já possui uma função para esse tipo de tarefa.\n\n$text = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. In suscipit convallis neque non suscipit. Nunc interdum ultrices ultrices. Interdum et malesuada fames ac ante ipsum primis in faucibus. Donec id justo tincidunt, porta mi vitae, sodales nibh. Nulla quis velit at erat maximus porta. Mauris sit amet consequat ligula. Vivamus congue pretium fermentum. Duis non lorem sodales, aliquam sapien quis, sodales elit. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Vestibulum ut ex ultricies, iaculis velit a, suscipit sem. Maecenas pharetra est vitae ipsum posuere, ac elementum lorem condimentum. Maecenas congue ac magna euismod euismod.';\n\necho wp_trim_words($text, $numWords = 10, '...');\n\n\nNo código acima é utilizada a função wp_trim_words que possui três parâmetros. O primeiro é o texto (Lorem Ipsum) que será cortado, o segundo significa quantas palavras serão mostradas e o último é o que vai ser concatenado com texto após o corte. Para exemplificar utilizei um trecho de um Lorem Ipsum. O resultado ficará assim:\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. In suscipit...\n\n\nUsar o atributo posts\n\nEm projetos que usam Wordpress é muito comum encontrarmos consultas utilizando WP_Query e em seguida percorrer os resultados utilizando um while conforme no exemplo abaixo:\n\n&lt;?php \n\n// Montamos a query\n$query = new WP_Query([\n    'post_type'      =&gt; 'post-type-example',\n    'post_status'    =&gt; 'publish',\n    'posts_per_page' =&gt; 5\n]);\n\n?&gt;\n\n// Verifica se possui posts e depois integra o resultado com a estrutura HTML\n&lt;?php if ($query-&gt;have_posts()): ?&gt;\n    &lt;ul&gt;\n        &lt;?php while ($query-&gt;have_posts()): $query-&gt;the_post(); ?&gt;\n            &lt;li&gt;&lt;?php echo get_the_title() ?&gt;&lt;/li&gt;\n        &lt;?php endwhile ?&gt;\n    &lt;/ul&gt;\n    \n    // Reseta a query para não conflitar com outras consultas\n    &lt;?php wp_reset_postdata() ?&gt;\n&lt;?php endif ?&gt;\n\n\nAgora um exemplo usando o atributo posts. O objeto WP_Query tem o atributo posts  que é um array e podemos usar com  foreach conforme o PHP sugere.\n\n&lt;?php \n\n// Montamos a query\n$query = new WP_Query([\n    'post_type'      =&gt; 'post-type-example',\n    'post_status'    =&gt; 'publish',\n    'posts_per_page' =&gt; 5\n]);\n\n?&gt;\n\n// Verifica se possui posts e depois integra o resultado com a estrutura HTML\n&lt;?php if ($query-&gt;posts): ?&gt;\n    &lt;ul&gt;\n        &lt;?php foreach ($query-&gt;posts as $item): ?&gt;\n            &lt;li&gt;&lt;?php echo $item-&gt;post_title ?&gt;&lt;/li&gt;\n        &lt;?php endforeach ?&gt;\n    &lt;/ul&gt;\t\n&lt;?php endif ?&gt;\n\nDo meu ponto de vista, com esta abordagem fica mais simples de efetuar uma leitura em código.\n\nFunção wp_list_pluck\n\nOutra situação que encontrei em muitos projetos foi de que a lógica usada precisava verificar se existiam IDs de uma query em um array. Até aí tudo bem, mas para obter os IDs da consulta, o desenvolvedor criou uma função separada que retornava um outro array contendo somente os IDs. Como no exemplo abaixo:\n\n// Função para retornar IDs\nfunction get_ids($query) {\n\n    // Se não tem posts\n    if (!$query-&gt;posts) {\n        return false;\n    }\n\n    // array vazios para inserir os ids\n    $ids = [];\n\n    // percorre a consulta usando o atributo posts =DDD\n    foreach ($query-&gt;posts as $item) {\n        \n        // Insere os IDs no array\n        $ids[] = $item-&gt;ID;\n    }\n\n    // Se o array não estiver vazio retorna os ids, senão retorna false\n    return count($ids) &gt; 0 ? $ids : false;\n}\n\n\nEm seguida usa a função da seguinte forma:\n\n// Monta a Query\n$query = new WP_Query([\n    'post_type'      =&gt; 'post-type-example',\n    'post_status'    =&gt; 'publish',\n    'posts_per_page' =&gt; -1\n]);\n\n// Obtém os ids\n$ids = get_ids($query);\n\n// Aplica a sua lógica\nif (is_array($ids) &amp;&amp; in_array($ids, $array)) {\n    // ...\n}\n\n\nContudo, o Worpress tem a função que resolve o problema de uma forma mais simples, sem precisar implementar a get_ids. Basta apenas passar um array que possuam os mesmos indíces.\n\n// Monta a Query\n$query = new WP_Query([\n    'post_type'      =&gt; 'post-type-example',\n    'post_status'    =&gt; 'publish',\n    'posts_per_page' =&gt; -1\n]);\n\n// Obtém os ids\n$ids = wp_list_pluck($query-&gt;posts, 'ID');\n\n// Aplica a lógica\nif (in_array($ids, $array)) {\n    // ...\n}\n\nAlém de termos mais um motivo para usar o atributo posts também conseguimos econimizar algumas linhas de código =D\n\nAtualização da versão e plugins\n\nPor último, mas não menos importante, é importante lembrar para sempre trabalharem com as últimas versões de plugins e do Wordpress, pois é um dos gerenciadores de conteúdo mais usados no mundo e com isso é alvo de muitas tentativas de invasão. Constantemente estão sendo lançadas correções não somente de bugs, mas também de brechas de segurança. A não atualização também gera problemas de compatibilidade com plugins que por sua vez param de funcionar da forma que se espera.\n\nConsiderações\n\nSe você tiver alguma dúvida, sugestão ou crítica fique a vontade para comentar :)\n\n",
        "url": "/2019/04/06/dicas-desenvolvimento-wordpress/"
      },
    
      {
        "title": "Wordpress Development Tips",
        "excerpt": "This text is a few different from previous texts where I’ve talked about data subjects. Here I intent to illustrate some tips on projects wordpress development.\n",
        "content": "Portuguese Version\n\nThis text is a few different from previous texts where I’ve talked about data subjects. Here I intent to illustrate some tips on projects Wordpress development.\n\nTransaction\n\nMany times we need to import data that will be used to show in any project. The importation process can generate some errors when is running, thus, we need to ensure that in this cases don’t be imported incomplete information. Therefore, for these situations is correct to use transactions. Of course, there are many purposes which don’t have relation with importation tasks.\n\nfunction addPostExample() {\n\n    // Global variable from Wordpress\n    global $wpdb; \n    \n    // I start the transtation\n    $wpdb-&gt;query('START TRANSACTION');\n    \n    // I define some data for the post\n    $postData = [\n        'post_title'     =&gt; 'Title example',  \n        'post_type'      =&gt; 'post-type-example',\n        'post_status'    =&gt; 'publish',\n        'comment_status' =&gt; 'closed',\n        'ping_status'    =&gt; 'closed'\n    ];\n    \n    // The post is recorded\n    $postExample = wp_insert_post($postData, true);\n\n    // Is there some error?\n    if (is_wp_error($postExample)) {\n        \n        // If yes, we do rollback\n        $wpdb-&gt;query('ROLLBACK');\n        return;\n    } \n    \n    // Is not there an error? Then is save the post\n    $wpdb-&gt;query('COMMIT');\n        \n    // Returns the post id\n    return $postExample;\n}\n\n\nTruncate text\n\nA situation that happens many times is when we need to show only part of the content (ie preview to text from the blog).\n\nI worked in projects where developers built a function to cut content by the quantity of the words, but there would have no necessity because the Wordpress has a function that does that.\n\n$text = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. In suscipit convallis neque non suscipit. Nunc interdum ultrices ultrices. Interdum et malesuada fames ac ante ipsum primis in faucibus. Donec id justo tincidunt, porta mi vitae, sodales nibh. Nulla quis velit at erat maximus porta. Mauris sit amet consequat ligula. Vivamus congue pretium fermentum. Duis non lorem sodales, aliquam sapien quis, sodales elit. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Vestibulum ut ex ultricies, iaculis velit a, suscipit sem. Maecenas pharetra est vitae ipsum posuere, ac elementum lorem condimentum. Maecenas congue ac magna euismod euismod.';\n\necho wp_trim_words($text, $numWords = 10, '...');\n\n\nOn the code above is used the function wp_trim_words which has three arguments. The first is the text (Lorem Ipsum) that will be cut, the second argument means the number of words which will be showed and the last is what will be concatenated with words. The o result is going to be like this:\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. In suscipit...\n\n\nUse the posts attribute\n\nAnother situation that happens on Wordpress projects is we found queries with WP_Query and after that is used while to show the results. See the example below:\n\n&lt;?php \n\n// I built the query\n$query = new WP_Query([\n    'post_type'      =&gt; 'post-type-example',\n    'post_status'    =&gt; 'publish',\n    'posts_per_page' =&gt; 5\n]);\n\n?&gt;\n\n// I verify if there are posts and after I merge posts with HTML\n&lt;?php if ($query-&gt;have_posts()): ?&gt;\n    &lt;ul&gt;\n        &lt;?php while ($query-&gt;have_posts()): $query-&gt;the_post(); ?&gt;\n            &lt;li&gt;&lt;?php echo get_the_title() ?&gt;&lt;/li&gt;\n        &lt;?php endwhile ?&gt;\n    &lt;/ul&gt;\n    \n    // I reset the query to avoid conflicts with other queries\n    &lt;?php wp_reset_postdata() ?&gt;\n&lt;?php endif ?&gt;\n\nNow, an example using the posts attribute. The object WP_Query has the posts attribute which is an array and we can use with foreach as the PHP suggests.\n\n&lt;?php \n\n// I built the query\n$query = new WP_Query([\n    'post_type'      =&gt; 'post-type-example',\n    'post_status'    =&gt; 'publish',\n    'posts_per_page' =&gt; 5\n]);\n\n?&gt;\n\n// I verify if there are posts and after I merge posts with HTML\n&lt;?php if ($query-&gt;posts): ?&gt;\n    &lt;ul&gt;\n        &lt;?php foreach ($query-&gt;posts as $item): ?&gt;\n            &lt;li&gt;&lt;?php echo $item-&gt;post_title ?&gt;&lt;/li&gt;\n        &lt;?php endforeach ?&gt;\n    &lt;/ul&gt;\t\n&lt;?php endif ?&gt;\n\nFrom my point of view, with this approach get simpler to read the code.\n\nFunction wp_list_pluck\n\nAnother situation that I found out in many projects was the logic from the developer would need to verify if a set of IDs from a query were within an array. Until this point is ok, but to get the IDs the developer created a function where was returned another array only with IDs. As in the following example.\n\n// Function that returns IDs\nfunction get_ids($query) {\n\n    // if there are no posts\n    if (!$query-&gt;posts) {\n        return false;\n    }\n\n    // clear array to insert IDs\n    $ids = [];\n\n    // read posts using posts attribute =D\n    foreach ($query-&gt;posts as $item) {\n        \n        // Insert IDs in array\n        $ids[] = $item-&gt;ID;\n    }\n\n    // if the array is not clear then returns the IDs, else return false\n    return count($ids) &gt; 0 ? $ids : false;\n}\n\n\nThen, he uses the function like this:\n\n// He built the query\n$query = new WP_Query([\n    'post_type'      =&gt; 'post-type-example',\n    'post_status'    =&gt; 'publish',\n    'posts_per_page' =&gt; -1\n]);\n\n// Get the IDs\n$ids = get_ids($query);\n\n// He applies his logic\nif (is_array($ids) &amp;&amp; in_array($ids, $array)) {\n    // ...\n}\n\nHowever, the Wordpress has a function that figures out the problem with way easier, without to need to implement the get_ids. Is only put an array as an argument and this array needs to have the same indexes.\n\n// Built de query\n$query = new WP_Query([\n    'post_type'      =&gt; 'post-type-example',\n    'post_status'    =&gt; 'publish',\n    'posts_per_page' =&gt; -1\n]);\n\n// Get the IDs\n$ids = wp_list_pluck($query-&gt;posts, 'ID');\n\n// Apply the logics\nif (in_array($ids, $array)) {\n    // ...\n}\n\nBeyond we have one more reason to use the posts attribute also we can save some code lines =D\n\nUpdate version and plugins\n\nAnd for last, but not less important, is important you remember to work with the last version of the plugins and Wordpress because it is one of the content managers more used in the world and like that is a target of many hacker’s attacks. Constantly are launched security and bugs corrections. If you don’t update, there are great chances of you have problems with compatibility with plugins and they stop working as you hope.\n\nConsiderations\n\nIf you have some doubt, suggestion or critics, feel free to comment :)\n\n",
        "url": "/2019/04/06/wordpress-development-tips/"
      },
    
      {
        "title": "Regressão Linear Simples",
        "excerpt": "Hoje eu vou falar sobre os meus estudos com Regressão Linar e mostrar com um simples exemplo.\n",
        "content": "Hoje eu vou falar sobre os meus estudos com Regressão Linar e mostrar com um simples exemplo. Para este conteúdo, eu procurei no Kaggle e encontrei o dataset Beer Consumption - Sao Paulo. Como o nome diz, este possui dados referente ao consumo de cerveja e neste post eu quero descobrir o que ajuda a variar o consumo.\n\nPrimeiramente, eu importei as bibliotecas e o dataset para visualizar as colunas.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\n\nbase = pd.read_csv('dataset.csv')\nbase.head()\n\n\n\n\nDepois disso, eu percebi que havia um monte de linhas em branco.\n\n\n\nPara ser exato, no dataset havia 576 linhas em branco. Para saber quantas delas eram valores nulos, eu executei o código abaixo.\n\nbase.isna().sum()\n\n\nE obtive a seguinte tabela.\n\n\n\nDepois de levantar as informações acima, eu precisei limpar as linhas inúteis. Para fazer isso eu executei:\n\nbase = base.dropna()\n\n\nEntão, antes de eu descobrir uma variável que eu usei para correlacionar com beer_consumption eu precisei ver se os dados estavam normalizados.\n\n# pego os valores da última coluna (beer_consumption)\nconsumption = base.iloc[:, -1].values\nplt.hist(consumption)\n\n\nO código mostrou isso:\n\n\n\nNo gráfico, eu vi que os dados estavam normalizados e com esta pré-condição, eu queria saber qual variável correlacionar, entender e prever o consumo de cerveja. Para isso, eu gerei um mapa de calor e eu pude ver qual variável tinha a relação mais forte.\n\nMas antes de visualizar o gráfico, foi preciso converter as variáveis, porque elas foram importadas como strings.\n\n# substitui virgual por ponto e converte os valores\nbase['avg_temperature'] = base['avg_temperature'].str.replace(',', '.')\nbase['avg_temperature'] = base['avg_temperature'].astype(float)\n\nbase['min_temperature'] = base['min_temperature'].str.replace(',', '.')\nbase['min_temperature'] = base['min_temperature'].astype(float)\n\nbase['max_temperature'] = base['max_temperature'].str.replace(',', '.')\nbase['max_temperature'] = base['max_temperature'].astype(float)\n\nbase['min_temperature'] = base['min_temperature'].str.replace(',', '.')\nbase['min_temperature'] = base['min_temperature'].astype(float)\n\nbase['precipitation'] = base['precipitation'].str.replace(',', '.')\nbase['precipitation'] = base['precipitation'].astype(float)\n\nbase['is_weekend'] = base['is_weekend'].astype(bool)\n\n\nPara gerar o mapa de calor eu usei a bibliocate Seaborn.\n\nsns.heatmap(base.corr(), annot=True)\n\nO mapa de calor mostrou isto:\n\n\n\nCom a imagem do mapa de calor, eu pude ver melhor a relação entre beer_consumption e max_temperature. A força desta correlação era de 0.64 and e tinha uma nível moderado.\n\nOs próximos passos foram entender o comportamente entre ambas variáveis através de um gráfico de dispersão.\n\n# valores do eixo x\nx = base['max_temperature'].values\nx = x.reshape(-1, 1)\n# valores do eixo y\ny = base['beer_consumption'].values\nplt.scatter(x, y)\n\nO gráfico me mostrou que conforme cresce max_temperature, também cresce beer_consumption.\n\n\n\nAntes de prever o consumo de cerveja, era preciso treinar os dados.\n\nmodel = LinearRegression()\nmodel.fit(x, y)\n\nCom os dados treinados, eu mostrei uma linha para os valores que foram previstos.\n\n\n\nPara finalizar, uma outra experiência é tentar predizer um valor sozinho. Como por exemplo, eu vou tentar prever o consumo de cerveja com uma temperatura máxim de 38º.\n\nmodel.predict(38)\n# Saída: array([ 32.85907157])\n\nOu seja, com uma temperatura de 38º, o consumo seria de 32 litros.\n\nEu espero que tenham gostado do post. Qualquer dúvida ou sugestão é só deixar um comentário.\n",
        "url": "/2019/10/14/regressao-linear-simples/"
      },
    
      {
        "title": "Simple Linear Regression",
        "excerpt": "Today I’m going to talk about my studies with Linear Regression and show with a simple example.\n",
        "content": "Today I’m going to talk about my studies with Linear Regression and show with a simple example. For this content, I searched on Kaggle and found the Beer Consumption - Sao Paulo dataset. As the name says, this one owns data about beer consumption and on this post, I want to find out what helps to vary the consumption.\n\nFirstly, I imported the libs and the dataset to visualize the columns.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\n\nbase = pd.read_csv('dataset.csv')\nbase.head()\n\n\n\n\nAfter this, I perceived that there was a lot of empty lines.\n\n\n\nTo be exact, on the dataset there were 576 empty lines. To know how much registers were NaN, I executed the code below.\n\nbase.isna().sum()\n\n\nAnd I got the following table.\n\n\n\nAfter raising the information above, I needed to clean useless lines. To do this I executed:\n\nbase = base.dropna()\n\n\nSo, before I find a variable that I used to correlate with beer_consumption I needed to see whether the data was normalized. For this, I plotted a histogram graph.\n\n# get the last column values (beer_consumption)\nconsumption = base.iloc[:, -1].values\nplt.hist(consumption)\n\n\nThe code showed this:\n\n\n\nIn the chart, I saw that the data was normalized and with this precondition, I would want to know which variable to correlate, to understand and to predict the beer consumption. For that, I generate a heatmap and I could see which variable had the strongest relation.\n\nBut before to plot the chart, I need to convert the variables, because they imported as string types.\n\n# replace comma by the dot and convert the values\nbase['avg_temperature'] = base['avg_temperature'].str.replace(',', '.')\nbase['avg_temperature'] = base['avg_temperature'].astype(float)\n\nbase['min_temperature'] = base['min_temperature'].str.replace(',', '.')\nbase['min_temperature'] = base['min_temperature'].astype(float)\n\nbase['max_temperature'] = base['max_temperature'].str.replace(',', '.')\nbase['max_temperature'] = base['max_temperature'].astype(float)\n\nbase['min_temperature'] = base['min_temperature'].str.replace(',', '.')\nbase['min_temperature'] = base['min_temperature'].astype(float)\n\nbase['precipitation'] = base['precipitation'].str.replace(',', '.')\nbase['precipitation'] = base['precipitation'].astype(float)\n\nbase['is_weekend'] = base['is_weekend'].astype(bool)\n\n\nTo generate the heatmap I used the Seaborn library.\n\nsns.heatmap(base.corr(), annot=True)\n\n\nThe heatmap showed this:\n\n\n\nWith the heatmap image, I could see that better relation with beer_consumption was max_temperature. The strong this correlation was 0.64 and it had a modered level.\n\nThe next steps were to understand the behavior between both variables through the scatter chart.\n\n# values to X axis\nx = base['max_temperature'].values\nx = x.reshape(-1, 1)\n# values to Y axis \ny = base['beer_consumption'].values\nplt.scatter(x, y)\n\n\nThe chart showed me that according max_temperature grows, also grows the beer_consumption.\n\n\n\nBefore to predict the beer_consumption, I needed to train the data.\n\nmodel = LinearRegression()\nmodel.fit(x, y)\n\n\nWith data trained, I showed a line to values that were predicted.\n\n\n\nTo finish, another experience is to try to predict a single value. As e.g, I’m going to predict a beer_consumption with a max_temperature of 38 degrees celsius.\n\nmodel.predict(38)\n# Output: array([ 32.85907157])\n\n\nIn other words, with a max_temperature of 38 degrees Celcius, the beer_consumption would be 32 liters.\n\nI hope you have liked this post. Any doubt or suggestions is only to write a comment.\n",
        "url": "/2019/10/14/simple-with-linear-regression/"
      },
    
  
  
  
  {
    "title": "Search",
    "excerpt": "\n",
    "content": "{% include site-search.html %}\n",
    "url": "/search/"
  }
  
]

